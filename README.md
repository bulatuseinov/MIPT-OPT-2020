# Quasi Newton optimization methods in context of Deep Learning 
## Research project for the course of optimization methods as MIPT.
### Spring 2020
### Authors:
- [Alexander Zhogov][Sasha]
- [Mikhail Sysak][Miha]
- [Bulat Useinov][Bulat]
### Academic supervisor:
- [Alexandr Katrutsa][amkatrutsa]

In this [article][paper], we tried to demonstrate the suitability of **Quasi Newton** optimization methods for **Deep Learning** problems. We conducted a series of experiments and compared different approaches of optimization with each other.

(Only Russian version is currently available)

[//]: # (This actually is the most platform independent comment)

  [Board]: <https://columns.me/mipt_opt_2020/mipt-opt-2020-vas>
  [Sasha]: <https://github.com/zhog96/>
  [Miha]: <https://github.com/sysak-ma/>
  [Bulat]: <https://github.com/bulatuseinov/>
  [amkatrutsa]: <https://github.com/amkatrutsa/>
  [paper]: <https://github.com/bulatuseinov/MIPT-OPT-2020/blob/master/MIPT_OPT_2020.pdf>
  
  
