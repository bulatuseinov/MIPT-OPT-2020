@ARTICLE{adam,
    title={Adam: A Method for Stochastic Optimization},
    author={Diederik P. Kingma and Jimmy Ba},
    year={2014},
    eprint={1412.6980},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@ARTICLE{barzilaiborwein,
    title={Barzilai-Borwein Step Size for Stochastic Gradient Descent},
    author={Conghui Tan and Shiqian Ma and Yu-Hong Dai and Yuqiu Qian},
    year={2016},
    eprint={1605.04131},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@BOOK{onlineBFGS,
  title = 	 {A Stochastic Quasi-Newton Method for Online Convex Optimization},
  author = 	 {Nicol N. Schraudolph and Jin Yu and Simon Günter},
  booktitle = 	 {Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics},
  pages = 	 {436--443},
  year = 	 {2007},
  editor = 	 {Marina Meila and Xiaotong Shen},
  volume = 	 {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {San Juan, Puerto Rico},
  month = 	 {21--24 Mar},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v2/schraudolph07a/schraudolph07a.pdf},
  url = 	 {http://proceedings.mlr.press/v2/schraudolph07a.html},
  abstract = 	 {We develop stochastic variants of the well-known BFGS quasi-Newton optimization method, in both full and memory-limited (LBFGS) forms, for online optimization of convex functions. The resulting algorithm performs comparably to a well-tuned natural gradient descent but is scalable to very high-dimensional problems. On standard benchmarks in natural language processing, it asymptotically outperforms previous stochastic gradient methods for parameter estimation in conditional random fields. We are working on analyzing the convergence of online (L)BFGS, and extending it to nonconvex optimization problems.}
}

@ARTICLE{sampledbfgs,
    title={Quasi-Newton Methods for Deep Learning: Forget the Past, Just Sample},
    author={Albert S. Berahas and Majid Jahani and Martin Takáč},
    year={2019},
    eprint={1901.09997},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@BOOK{numopt,
  title={Numerical optimization},
  author={Nocedal, Jorge and Wright, Stephen},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@ARTICLE{multibatchLBFGS,
    title={A Multi-Batch L-BFGS Method for Machine Learning},
    author={Albert S. Berahas and Jorge Nocedal and Martin Takáč},
    year={2016},
    eprint={1605.06049},
    archivePrefix={arXiv},
    primaryClass={math.OC}
}

@ARTICLE{BB-DL,
  title={Barzilai--Borwein-based adaptive learning rate for deep learning},
  author={Liang, Jinxiu and Xu, Yong and Bao, Chenglong and Quan, Yuhui and Ji, Hui},
  journal={Pattern Recognition Letters},
  volume={128},
  pages={197--203},
  year={2019},
  publisher={Elsevier}
}

@ARTICLE{MNIST,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@TECHREPORT{CIFAR10,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}
